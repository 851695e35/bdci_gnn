{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T16:53:15.084158200Z",
     "start_time": "2023-11-24T16:53:15.019648100Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liqiang/software/miniconda3/envs/pyg/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "62e14f50eaa6077f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T16:53:15.084158200Z",
     "start_time": "2023-11-24T16:53:15.041148400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    file = \"data/raw/train_90.csv\"\n",
    "    train_data = pd.read_csv(file)\n",
    "    return train_data\n",
    "\n",
    "\n",
    "def get_test_data():\n",
    "    file = \"data/raw/A榜/node_test_4_A.csv\"\n",
    "    test_data = pd.read_csv(file)\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "156e0497018991f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T16:53:15.111606400Z",
     "start_time": "2023-11-24T16:53:15.055151600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        # Layer 1\n",
    "        self.fc1 = nn.Linear(36, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.drop1 = nn.Dropout(p=0.3)\n",
    "\n",
    "        # Layer 2\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.drop2 = nn.Dropout(p=0.4)\n",
    "\n",
    "        # Layer 3\n",
    "        self.fc3 = nn.Linear(256, 512)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.drop3 = nn.Dropout(p=0.5)\n",
    "\n",
    "        # Layer 4\n",
    "        self.fc4 = nn.Linear(512, 1024)\n",
    "        self.bn4 = nn.BatchNorm1d(1024)\n",
    "        self.drop4 = nn.Dropout(p=0.6)\n",
    "\n",
    "        # Output Layer\n",
    "        self.fc5 = nn.Linear(1024, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.drop1(F.relu(self.bn1(self.fc1(x))))\n",
    "        out = self.drop2(F.relu(self.bn2(self.fc2(out))))\n",
    "        out = self.drop3(F.relu(self.bn3(self.fc3(out))))\n",
    "        out = self.drop4(F.relu(self.bn4(self.fc4(out))))\n",
    "        out = self.fc5(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5b966670a28cc656",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T16:53:15.113610500Z",
     "start_time": "2023-11-24T16:53:15.071155300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv1d(in_channels=36, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=1, stride=1)\n",
    "        self.drop1 = nn.Dropout(p=0.1)\n",
    "\n",
    "        # Layer 2\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=1, stride=1)\n",
    "        self.drop2 = nn.Dropout(p=0.1)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(128, 256)\n",
    "        self.drop3 = nn.Dropout(p=0.1)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), x.size(1), -1)\n",
    "        out = self.drop1(self.pool1(F.relu(self.conv1(x))))\n",
    "        out = self.drop2(self.pool2(F.relu(self.conv2(out))))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.drop3(F.relu(self.fc1(out)))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c68582c3d48f861a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T16:53:15.134622400Z",
     "start_time": "2023-11-24T16:53:15.089159300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, scheduler, epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "34782eaf2beacea5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T16:53:15.134622400Z",
     "start_time": "2023-11-24T16:53:15.117858800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(model, test_data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(test_data)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "465b9a88e56feae9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T16:53:15.689875800Z",
     "start_time": "2023-11-24T16:53:15.133622100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102600, 36)\n",
      "(102600, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "d = get_train_data()\n",
    "t = get_test_data()\n",
    "ans = []\n",
    "data = d.iloc[:, :]\n",
    "test = t.iloc[:, 1:]\n",
    "X = data.iloc[:, 1:37]\n",
    "X=RobustScaler().fit_transform(X)\n",
    "test=RobustScaler().fit_transform(test)\n",
    "y1 = data['active_index'].values\n",
    "y2 = data['consume_index'].values\n",
    "y = data.iloc[:, 37:]\n",
    "scaler = StandardScaler()\n",
    "y = scaler.fit_transform(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6a22be75b7474160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T16:56:45.412292Z",
     "start_time": "2023-11-24T16:53:15.683541400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.1157111620107791\n",
      "Epoch 2/50, Loss: 0.05133518530636506\n",
      "Epoch 3/50, Loss: 0.040252388081051166\n",
      "Epoch 4/50, Loss: 0.03488423731967695\n",
      "Epoch 5/50, Loss: 0.02985357591171663\n",
      "Epoch 6/50, Loss: 0.030715850451287635\n",
      "Epoch 7/50, Loss: 0.025782671369184877\n",
      "Epoch 8/50, Loss: 0.027727766694069057\n",
      "Epoch 9/50, Loss: 0.022993136392418585\n",
      "Epoch 10/50, Loss: 0.021384309498857976\n",
      "Epoch 11/50, Loss: 0.01738927488742475\n",
      "Epoch 12/50, Loss: 0.018468091127339593\n",
      "Epoch 13/50, Loss: 0.016674272551147867\n",
      "Epoch 14/50, Loss: 0.01643550866271864\n",
      "Epoch 15/50, Loss: 0.016376282442639816\n",
      "Epoch 16/50, Loss: 0.014650870352621165\n",
      "Epoch 17/50, Loss: 0.014799625321321579\n",
      "Epoch 18/50, Loss: 0.014944480435964547\n",
      "Epoch 19/50, Loss: 0.01464901602318385\n",
      "Epoch 20/50, Loss: 0.014997448458654476\n",
      "Epoch 21/50, Loss: 0.012681154268294425\n",
      "Epoch 22/50, Loss: 0.013545417424263502\n",
      "Epoch 23/50, Loss: 0.01227394102299191\n",
      "Epoch 24/50, Loss: 0.012440530670356201\n",
      "Epoch 25/50, Loss: 0.01184883365231076\n",
      "Epoch 26/50, Loss: 0.012325282900726557\n",
      "Epoch 27/50, Loss: 0.012567762232053458\n",
      "Epoch 28/50, Loss: 0.01157549338675385\n",
      "Epoch 29/50, Loss: 0.011495018387190125\n",
      "Epoch 30/50, Loss: 0.011606734366785559\n",
      "Epoch 31/50, Loss: 0.010972006010713794\n",
      "Epoch 32/50, Loss: 0.011649897802816216\n",
      "Epoch 33/50, Loss: 0.010423512931941008\n",
      "Epoch 34/50, Loss: 0.010565680397112396\n",
      "Epoch 35/50, Loss: 0.010331144587756913\n",
      "Epoch 36/50, Loss: 0.0105364852982046\n",
      "Epoch 37/50, Loss: 0.010470539964317458\n",
      "Epoch 38/50, Loss: 0.010489863763909387\n",
      "Epoch 39/50, Loss: 0.010248303853504899\n",
      "Epoch 40/50, Loss: 0.009827762967593355\n",
      "Epoch 41/50, Loss: 0.0099258472657579\n",
      "Epoch 42/50, Loss: 0.010025967118049277\n",
      "Epoch 43/50, Loss: 0.009536803402749826\n",
      "Epoch 44/50, Loss: 0.009745725467708194\n",
      "Epoch 45/50, Loss: 0.009608364538603144\n",
      "Epoch 46/50, Loss: 0.009613995048962999\n",
      "Epoch 47/50, Loss: 0.009598768557749335\n",
      "Epoch 48/50, Loss: 0.009883153943247406\n",
      "Epoch 49/50, Loss: 0.009354451595761457\n",
      "Epoch 50/50, Loss: 0.009465144763693697\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "X_train = torch.Tensor(X)\n",
    "X_test = torch.Tensor(test)\n",
    "y_train = torch.Tensor(y)\n",
    "\n",
    "batch_size = 256\n",
    "epoch_num = 50\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train(model, train_loader, criterion, optimizer, scheduler, epochs=epoch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "27cb097e2ca54c76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T16:56:47.687959200Z",
     "start_time": "2023-11-24T16:56:45.401262400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(X_test)\n",
    "test_loader = DataLoader(test_dataset)\n",
    "\n",
    "# 进行预测\n",
    "predictions = []\n",
    "for test_data in test_loader:\n",
    "    pred = predict(model, test_data[0])\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a8223ac058f7769d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T17:01:24.873115200Z",
     "start_time": "2023-11-24T17:01:24.848818100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4560, 2)\n",
      "[-0.5301677 -1.0551057]\n"
     ]
    }
   ],
   "source": [
    "# 将包含 PyTorch Tensor 的列表连接成一个 4560x2 的矩阵\n",
    "p = torch.cat(predictions, dim=0).numpy()\n",
    "\n",
    "# 打印矩阵的形状和第一个元素\n",
    "print(p.shape)\n",
    "print(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e1a2353c0afabce6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T17:01:41.981762500Z",
     "start_time": "2023-11-24T17:01:41.948177900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68.426834 60.645542]\n",
      " [67.99642  62.33435 ]\n",
      " [68.28324  62.488197]\n",
      " ...\n",
      " [73.24848  82.81422 ]\n",
      " [73.28857  82.79428 ]\n",
      " [74.05747  83.91006 ]]\n"
     ]
    }
   ],
   "source": [
    "p = scaler.inverse_transform(p)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "7cee654731034026",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T17:03:16.840346100Z",
     "start_time": "2023-11-24T17:03:16.722221700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "ans = []\n",
    "for i in range(len(p)):\n",
    "        s = str(t['geohash_id'].iloc[i])\n",
    "        s += '\\t'\n",
    "        s += str(p[i][1])\n",
    "        s += '\\t'\n",
    "        s += str(p[i][0])\n",
    "        s += '\\t'\n",
    "        s += str(t['date_id'].iloc[i])\n",
    "        ans.append(s)\n",
    "\n",
    "df = pd.DataFrame(data=ans, columns=[\"geohash_id\\tconsumption_level\\tactivity_level\\tdate_id\"])\n",
    "df.to_csv(\"CNN.csv\", index=False)\n",
    "print(\"finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
