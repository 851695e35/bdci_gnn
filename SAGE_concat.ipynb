{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "114502f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch_geometric.nn as gnn\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.functional import F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "with open(\"data/concat_graph/train_graphs_data.pkl\", \"rb\") as file:\n",
    "    graphs = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, Data(x=[7980, 33], edge_index=[2, 85761], y=[7980, 2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs), graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2741, -0.6940])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[0].y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 划分训练集和验证集，使用sklearn的train_test_split函数\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_graphs, val_graphs = train_test_split(graphs, test_size=0.1, random_state=42)\n",
    "val_len = graphs[0].x.shape[0] // 1140\n",
    "train_graphs = graphs[:-val_len]\n",
    "val_graphs = graphs[-val_len:]\n",
    "len(train_graphs), len(val_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGEModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SAGEModel, self).__init__()\n",
    "\n",
    "        self.graph_features = nn.ModuleList(\n",
    "            [\n",
    "                gnn.SAGEConv(input_size, 128),\n",
    "                nn.LayerNorm(128),\n",
    "                nn.ReLU(),\n",
    "                gnn.SAGEConv(128, 128),\n",
    "                nn.LayerNorm(128),\n",
    "                nn.ReLU(),\n",
    "                gnn.SAGEConv(128, 128),\n",
    "                nn.LayerNorm(128),\n",
    "                nn.ReLU(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # 考虑更多的trick，如layernorm等等\n",
    "        self.regression = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.02),\n",
    "            nn.Linear(32, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        output = x\n",
    "\n",
    "        for layer in self.graph_features:\n",
    "            if isinstance(layer, gnn.SAGEConv):\n",
    "                output = layer(output, edge_index)\n",
    "            else:\n",
    "                output = layer(output)\n",
    "\n",
    "        output = self.regression(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7980, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 看看模型的输入输出\n",
    "model = SAGEModel(input_size=33, output_size=2)\n",
    "output = model(graphs[0])\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb002ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = graphs[0].x.shape[1]\n",
    "# 这里的output_size就是最终的输出维度，不需要再乘以num_heads\n",
    "output_size = graphs[0].y.shape[1]\n",
    "# 个人认为，注意力头的个数应该和输出维度保持一致，因为每个输出可能需要关注不同的邻居\n",
    "num_heads = graphs[0].y.shape[1]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1d2aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, criterion, optimizer, scheduler, train_graphs, val_graphs=None, num_epochs=50\n",
    "):\n",
    "    # 训练过程记录\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "\n",
    "    with tqdm(total=num_epochs, desc=\"Training Progress\", unit=\"epoch\") as pbar_epochs:\n",
    "        for epoch in range(num_epochs):\n",
    "            # 训练\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "\n",
    "            # 目前每个batch是1个graph\n",
    "            for i, graph in enumerate(train_graphs):\n",
    "                graph = graph.to(device)\n",
    "\n",
    "                output = model(graph)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(output, graph.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            train_loss /= len(train_graphs)\n",
    "            train_loss_list.append(train_loss)\n",
    "\n",
    "            # 验证\n",
    "            if val_graphs:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0.0\n",
    "                    for i, graph in enumerate(val_graphs):\n",
    "                        graph = graph.to(device)\n",
    "                        output = model(graph)\n",
    "                        loss = criterion(output, graph.y)\n",
    "                        val_loss += loss.item()\n",
    "                    val_loss /= len(val_graphs)\n",
    "                    val_loss_list.append(val_loss)\n",
    "\n",
    "            if val_graphs:\n",
    "                pbar_epochs.set_postfix(\n",
    "                    {\"train MSE Loss\": train_loss, \"val MSE Loss\": val_loss}\n",
    "                )\n",
    "            else:\n",
    "                pbar_epochs.set_postfix({\"train MSE Loss\": train_loss})\n",
    "\n",
    "            pbar_epochs.update(1)\n",
    "            # 学习率更新\n",
    "            scheduler.step()\n",
    "\n",
    "    # 可视化训练过程\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss_list, label=\"train loss\")\n",
    "    if val_graphs:\n",
    "        plt.plot(val_loss_list, label=\"val loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"MSE loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型、算法、损失函数\n",
    "model = SAGEModel(\n",
    "    input_size=input_size,\n",
    "    output_size=output_size,\n",
    ").to(device)\n",
    "# 考虑是否加入weight_decay\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "# 学习率衰减\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n",
    "# criterion = nn.MSELoss(reduction=\"sum\")\n",
    "criterion = nn.MSELoss().to(device)\n",
    "\n",
    "# model = train(\n",
    "#     model=model,\n",
    "#     criterion=criterion,\n",
    "#     optimizer=optimizer,\n",
    "#     scheduler=scheduler,\n",
    "#     train_graphs=train_graphs,\n",
    "#     val_graphs=val_graphs,\n",
    "#     num_epochs=150,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 所有数据放进去训一训"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型、算法、损失函数\n",
    "model = SAGEModel(\n",
    "    input_size=input_size,\n",
    "    output_size=output_size,\n",
    ").to(device)\n",
    "# 考虑是否加入weight_decay\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "# 学习率衰减\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n",
    "# criterion = nn.MSELoss(reduction=\"sum\")\n",
    "criterion = nn.MSELoss().to(device)\n",
    "\n",
    "# model = train(\n",
    "#     model=model,\n",
    "#     criterion=criterion,\n",
    "#     optimizer=optimizer,\n",
    "#     scheduler=scheduler,\n",
    "#     train_graphs=graphs,\n",
    "#     num_epochs=150,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model_path = \"saved/models/sage_concat.pth\"\n",
    "torch.save(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取模型\n",
    "model = torch.load(model_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取node_ids\n",
    "with open(\"data/concat_graph/node_ids.pkl\", \"rb\") as file:\n",
    "    node_ids = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7980"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(node_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取scaler\n",
    "import pickle\n",
    "\n",
    "with open(\"saved/scaler/label_scaler.pkl\", \"rb\") as file:\n",
    "    label_scaler = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取测试集\n",
    "with open(\"data/concat_graph/test_graphs_data.pkl\", \"rb\") as file:\n",
    "    test_graphs = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, Data(x=[7980, 33], edge_index=[2, 140370]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_graphs), test_graphs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [176,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/liqiang/workspace/datamining/datamining_dataset_1110/graph/bdci_gnn/SAGE_concat.ipynb 单元格 22\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.60.150.62/home/liqiang/workspace/datamining/datamining_dataset_1110/graph/bdci_gnn/SAGE_concat.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, graph \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(test_graphs):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.60.150.62/home/liqiang/workspace/datamining/datamining_dataset_1110/graph/bdci_gnn/SAGE_concat.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     graph \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.60.150.62/home/liqiang/workspace/datamining/datamining_dataset_1110/graph/bdci_gnn/SAGE_concat.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     output \u001b[39m=\u001b[39m model(graph)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.60.150.62/home/liqiang/workspace/datamining/datamining_dataset_1110/graph/bdci_gnn/SAGE_concat.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(output\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.60.150.62/home/liqiang/workspace/datamining/datamining_dataset_1110/graph/bdci_gnn/SAGE_concat.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# output_list.append(output.detach().cpu().numpy()[-len(node_ids) // 1140 :, :])\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.60.150.62/home/liqiang/workspace/datamining/datamining_dataset_1110/graph/bdci_gnn/SAGE_concat.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# print(output_list[-1].shape)\u001b[39;00m\n",
      "File \u001b[0;32m~/software/miniconda3/envs/pyg/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/liqiang/workspace/datamining/datamining_dataset_1110/graph/bdci_gnn/SAGE_concat.ipynb 单元格 22\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.60.150.62/home/liqiang/workspace/datamining/datamining_dataset_1110/graph/bdci_gnn/SAGE_concat.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph_features:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.60.150.62/home/liqiang/workspace/datamining/datamining_dataset_1110/graph/bdci_gnn/SAGE_concat.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(layer, gnn\u001b[39m.\u001b[39mSAGEConv):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.60.150.62/home/liqiang/workspace/datamining/datamining_dataset_1110/graph/bdci_gnn/SAGE_concat.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m         output \u001b[39m=\u001b[39m layer(output, edge_index)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.60.150.62/home/liqiang/workspace/datamining/datamining_dataset_1110/graph/bdci_gnn/SAGE_concat.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.60.150.62/home/liqiang/workspace/datamining/datamining_dataset_1110/graph/bdci_gnn/SAGE_concat.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m         output \u001b[39m=\u001b[39m layer(output)\n",
      "File \u001b[0;32m~/software/miniconda3/envs/pyg/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/software/miniconda3/envs/pyg/lib/python3.10/site-packages/torch_geometric/nn/conv/sage_conv.py:131\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[1;32m    130\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropagate(edge_index, x\u001b[39m=\u001b[39mx, size\u001b[39m=\u001b[39msize)\n\u001b[0;32m--> 131\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlin_l(out)\n\u001b[1;32m    133\u001b[0m x_r \u001b[39m=\u001b[39m x[\u001b[39m1\u001b[39m]\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_weight \u001b[39mand\u001b[39;00m x_r \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/software/miniconda3/envs/pyg/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/software/miniconda3/envs/pyg/lib/python3.10/site-packages/torch_geometric/nn/dense/linear.py:130\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    126\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "output_list = []\n",
    "with torch.no_grad():\n",
    "    for i, graph in enumerate(test_graphs):\n",
    "        graph = graph.to(device)\n",
    "        output = model(graph)\n",
    "        print(output.shape)\n",
    "        # output_list.append(output.detach().cpu().numpy()[-len(node_ids) // 1140 :, :])\n",
    "        # print(output_list[-1].shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, (1140, 2), array([-0.43294135, -1.0331519 ], dtype=float32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_list), output_list[0].shape, output_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缩放\n",
    "output_list = [label_scaler.inverse_transform(output) for output in output_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68.76068 , 60.836132], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 看看是不是缩放完成啦\n",
    "output_list[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把输出转成需要的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# 结果写入csv，分隔符为\\t\n",
    "output_path = \"output/sage_out.csv\"\n",
    "\n",
    "date_id = [20230404, 20230405, 20230406, 20230407]\n",
    "with open(output_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")  # 设置分隔符为制表符\n",
    "    writer.writerow([\"geohash_id\", \"consumption_level\", \"activity_level\", \"date_id\"])\n",
    "\n",
    "    # output_list.shape = [4天, 节点数, 2个输出]\n",
    "    for nidx in range(len(node_ids)):\n",
    "        for day in range(len(date_id)):\n",
    "            # 注意不要写反了\n",
    "            writer.writerow(\n",
    "                [\n",
    "                    node_ids[nidx],\n",
    "                    output_list[day][nidx][1],\n",
    "                    output_list[day][nidx][0],\n",
    "                    date_id[day],\n",
    "                ]\n",
    "            )\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
