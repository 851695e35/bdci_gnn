{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 这是一个baseline\n",
    "\n",
    "author：lq\n",
    "\n",
    "<del>把边信息加入节点特征，做lstm</del>\n",
    "\n",
    "发现节点之间在每天都有不同的连接，不止一个，因此无法将边特征加到节点上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前的lstm设置的时间步是1，相当于没有用到任何时序信息，网络退化为前馈网络\n",
    "\n",
    "所以本baseline中修改时间步 > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liqiang/software/miniconda3/envs/py37/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f756d69b270>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统一设置随机种子\n",
    "seed = 9999\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理\n",
    "\n",
    "<del>\n",
    "1. 读入节点和边的数据\n",
    "2. 把边的数据插入节点数据\n",
    "</del>\n",
    "\n",
    "边的信息仍然先不用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train_90.csv\", dtype={\"geohash_id\": str})\n",
    "df_test = pd.read_csv(\"data/A/node_test_4_A.csv\", dtype={\"geohash_id\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohash_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>F_1</th>\n",
       "      <th>F_2</th>\n",
       "      <th>F_3</th>\n",
       "      <th>F_4</th>\n",
       "      <th>F_5</th>\n",
       "      <th>F_6</th>\n",
       "      <th>F_7</th>\n",
       "      <th>F_8</th>\n",
       "      <th>...</th>\n",
       "      <th>F_28</th>\n",
       "      <th>F_29</th>\n",
       "      <th>F_30</th>\n",
       "      <th>F_31</th>\n",
       "      <th>F_32</th>\n",
       "      <th>F_33</th>\n",
       "      <th>F_34</th>\n",
       "      <th>F_35</th>\n",
       "      <th>active_index</th>\n",
       "      <th>consume_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4885e281g</td>\n",
       "      <td>20230104</td>\n",
       "      <td>-0.711</td>\n",
       "      <td>-0.696</td>\n",
       "      <td>-0.794</td>\n",
       "      <td>-0.727</td>\n",
       "      <td>-0.747</td>\n",
       "      <td>-0.792</td>\n",
       "      <td>1.539</td>\n",
       "      <td>2.433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.502</td>\n",
       "      <td>-0.456</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>-0.830</td>\n",
       "      <td>69.306</td>\n",
       "      <td>63.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4885e281g</td>\n",
       "      <td>20230105</td>\n",
       "      <td>-0.909</td>\n",
       "      <td>-0.903</td>\n",
       "      <td>-0.947</td>\n",
       "      <td>-0.844</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>-0.908</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>0.990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>-0.533</td>\n",
       "      <td>0.113</td>\n",
       "      <td>-0.887</td>\n",
       "      <td>68.881</td>\n",
       "      <td>61.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4885e281g</td>\n",
       "      <td>20230106</td>\n",
       "      <td>-0.920</td>\n",
       "      <td>-0.925</td>\n",
       "      <td>-0.923</td>\n",
       "      <td>-0.852</td>\n",
       "      <td>-0.853</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>0.792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>-0.564</td>\n",
       "      <td>-0.540</td>\n",
       "      <td>0.367</td>\n",
       "      <td>-1.021</td>\n",
       "      <td>69.738</td>\n",
       "      <td>61.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4885e281g</td>\n",
       "      <td>20230107</td>\n",
       "      <td>-0.926</td>\n",
       "      <td>-0.931</td>\n",
       "      <td>-0.943</td>\n",
       "      <td>-0.837</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-0.907</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>-0.554</td>\n",
       "      <td>-0.521</td>\n",
       "      <td>0.550</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>68.721</td>\n",
       "      <td>62.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4885e281g</td>\n",
       "      <td>20230108</td>\n",
       "      <td>-0.750</td>\n",
       "      <td>-0.764</td>\n",
       "      <td>-0.818</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.764</td>\n",
       "      <td>-0.816</td>\n",
       "      <td>1.116</td>\n",
       "      <td>1.447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.644</td>\n",
       "      <td>69.960</td>\n",
       "      <td>64.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102595</th>\n",
       "      <td>1d3640fad</td>\n",
       "      <td>20230330</td>\n",
       "      <td>2.049</td>\n",
       "      <td>1.751</td>\n",
       "      <td>2.777</td>\n",
       "      <td>2.968</td>\n",
       "      <td>3.008</td>\n",
       "      <td>2.544</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>-1.525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.019</td>\n",
       "      <td>2.920</td>\n",
       "      <td>2.533</td>\n",
       "      <td>3.210</td>\n",
       "      <td>-0.703</td>\n",
       "      <td>0.908</td>\n",
       "      <td>74.582</td>\n",
       "      <td>85.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102596</th>\n",
       "      <td>1d3640fad</td>\n",
       "      <td>20230331</td>\n",
       "      <td>1.871</td>\n",
       "      <td>1.733</td>\n",
       "      <td>2.613</td>\n",
       "      <td>3.218</td>\n",
       "      <td>3.286</td>\n",
       "      <td>2.700</td>\n",
       "      <td>-1.191</td>\n",
       "      <td>-1.861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.023</td>\n",
       "      <td>3.457</td>\n",
       "      <td>2.748</td>\n",
       "      <td>3.267</td>\n",
       "      <td>-0.908</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>73.194</td>\n",
       "      <td>86.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102597</th>\n",
       "      <td>1d3640fad</td>\n",
       "      <td>20230401</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.566</td>\n",
       "      <td>-2.486</td>\n",
       "      <td>-2.534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.018</td>\n",
       "      <td>1.517</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.275</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>72.713</td>\n",
       "      <td>79.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102598</th>\n",
       "      <td>1d3640fad</td>\n",
       "      <td>20230402</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.394</td>\n",
       "      <td>-2.585</td>\n",
       "      <td>-2.794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.016</td>\n",
       "      <td>1.194</td>\n",
       "      <td>0.779</td>\n",
       "      <td>1.017</td>\n",
       "      <td>-0.755</td>\n",
       "      <td>-0.707</td>\n",
       "      <td>72.394</td>\n",
       "      <td>78.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102599</th>\n",
       "      <td>1d3640fad</td>\n",
       "      <td>20230403</td>\n",
       "      <td>1.762</td>\n",
       "      <td>1.470</td>\n",
       "      <td>2.310</td>\n",
       "      <td>2.514</td>\n",
       "      <td>2.430</td>\n",
       "      <td>2.084</td>\n",
       "      <td>-0.895</td>\n",
       "      <td>-1.915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.014</td>\n",
       "      <td>2.924</td>\n",
       "      <td>2.482</td>\n",
       "      <td>2.555</td>\n",
       "      <td>-0.755</td>\n",
       "      <td>-0.695</td>\n",
       "      <td>71.646</td>\n",
       "      <td>84.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102600 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       geohash_id   date_id    F_1    F_2    F_3    F_4    F_5    F_6    F_7  \\\n",
       "0       4885e281g  20230104 -0.711 -0.696 -0.794 -0.727 -0.747 -0.792  1.539   \n",
       "1       4885e281g  20230105 -0.909 -0.903 -0.947 -0.844 -0.856 -0.908 -0.371   \n",
       "2       4885e281g  20230106 -0.920 -0.925 -0.923 -0.852 -0.853 -0.915 -0.334   \n",
       "3       4885e281g  20230107 -0.926 -0.931 -0.943 -0.837 -0.850 -0.907 -0.993   \n",
       "4       4885e281g  20230108 -0.750 -0.764 -0.818 -0.749 -0.764 -0.816  1.116   \n",
       "...           ...       ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "102595  1d3640fad  20230330  2.049  1.751  2.777  2.968  3.008  2.544 -0.503   \n",
       "102596  1d3640fad  20230331  1.871  1.733  2.613  3.218  3.286  2.700 -1.191   \n",
       "102597  1d3640fad  20230401 -0.099 -0.057  0.575  0.759  0.944  0.566 -2.486   \n",
       "102598  1d3640fad  20230402 -0.233 -0.232  0.498  0.599  0.842  0.394 -2.585   \n",
       "102599  1d3640fad  20230403  1.762  1.470  2.310  2.514  2.430  2.084 -0.895   \n",
       "\n",
       "          F_8  ...   F_28   F_29   F_30   F_31   F_32   F_33   F_34   F_35  \\\n",
       "0       2.433  ...  0.073  0.344  0.006 -0.446 -0.502 -0.456 -0.457 -0.830   \n",
       "1       0.990  ...  0.055  0.298  0.007 -0.523 -0.558 -0.533  0.113 -0.887   \n",
       "2       0.792  ...  0.067  0.324  0.006 -0.535 -0.564 -0.540  0.367 -1.021   \n",
       "3      -0.006  ...  0.076  0.276  0.010 -0.534 -0.554 -0.521  0.550 -0.211   \n",
       "4       1.447  ...  0.079  0.328  0.008 -0.468 -0.500 -0.419 -0.236  0.644   \n",
       "...       ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "102595 -1.525  ...  0.070  0.295  0.019  2.920  2.533  3.210 -0.703  0.908   \n",
       "102596 -1.861  ...  0.073  0.304  0.023  3.457  2.748  3.267 -0.908 -0.250   \n",
       "102597 -2.534  ...  0.070  0.299  0.018  1.517  0.975  1.275 -0.974 -0.765   \n",
       "102598 -2.794  ...  0.067  0.287  0.016  1.194  0.779  1.017 -0.755 -0.707   \n",
       "102599 -1.915  ...  0.067  0.284  0.014  2.924  2.482  2.555 -0.755 -0.695   \n",
       "\n",
       "        active_index  consume_index  \n",
       "0             69.306          63.78  \n",
       "1             68.881          61.62  \n",
       "2             69.738          61.03  \n",
       "3             68.721          62.02  \n",
       "4             69.960          64.62  \n",
       "...              ...            ...  \n",
       "102595        74.582          85.81  \n",
       "102596        73.194          86.31  \n",
       "102597        72.713          79.83  \n",
       "102598        72.394          78.72  \n",
       "102599        71.646          84.83  \n",
       "\n",
       "[102600 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单处理一下，做个标准化，去掉F_23和F_27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop([\"F_23\", \"F_27\"], axis=1, inplace=True)\n",
    "df_test.drop([\"F_23\", \"F_27\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化\n",
    "id_and_date_columns = [\"geohash_id\", \"date_id\"]\n",
    "feature_columns = df_train.drop(\n",
    "    [\"geohash_id\", \"date_id\", \"active_index\", \"consume_index\"], axis=1\n",
    ").columns\n",
    "label_columns = [\"active_index\", \"consume_index\"]\n",
    "\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "df_train.loc[:, feature_columns] = feature_scaler.fit_transform(\n",
    "    df_train[feature_columns]\n",
    ")\n",
    "label_scaler = StandardScaler()\n",
    "df_train.loc[:, label_columns] = label_scaler.fit_transform(df_train[label_columns])\n",
    "\n",
    "df_test.loc[:, feature_columns] = feature_scaler.transform(df_test[feature_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并两个数据集，并且按照geohash_id和date_id排序\n",
    "df_all = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "df_all.sort_values([\"geohash_id\", \"date_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohash_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>F_1</th>\n",
       "      <th>F_2</th>\n",
       "      <th>F_3</th>\n",
       "      <th>F_4</th>\n",
       "      <th>F_5</th>\n",
       "      <th>F_6</th>\n",
       "      <th>F_7</th>\n",
       "      <th>F_8</th>\n",
       "      <th>...</th>\n",
       "      <th>F_28</th>\n",
       "      <th>F_29</th>\n",
       "      <th>F_30</th>\n",
       "      <th>F_31</th>\n",
       "      <th>F_32</th>\n",
       "      <th>F_33</th>\n",
       "      <th>F_34</th>\n",
       "      <th>F_35</th>\n",
       "      <th>active_index</th>\n",
       "      <th>consume_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60840</th>\n",
       "      <td>007e3e4ef</td>\n",
       "      <td>20230104</td>\n",
       "      <td>-0.572895</td>\n",
       "      <td>-0.582853</td>\n",
       "      <td>-0.576396</td>\n",
       "      <td>-0.468212</td>\n",
       "      <td>-0.488368</td>\n",
       "      <td>-0.555685</td>\n",
       "      <td>0.089299</td>\n",
       "      <td>0.134324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738499</td>\n",
       "      <td>-0.065663</td>\n",
       "      <td>-0.457655</td>\n",
       "      <td>-0.579776</td>\n",
       "      <td>-0.640004</td>\n",
       "      <td>-0.559142</td>\n",
       "      <td>-0.518954</td>\n",
       "      <td>-0.999565</td>\n",
       "      <td>-0.061534</td>\n",
       "      <td>-0.203339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60841</th>\n",
       "      <td>007e3e4ef</td>\n",
       "      <td>20230105</td>\n",
       "      <td>-0.864671</td>\n",
       "      <td>-0.868830</td>\n",
       "      <td>-0.798404</td>\n",
       "      <td>-0.719249</td>\n",
       "      <td>-0.731408</td>\n",
       "      <td>-0.783150</td>\n",
       "      <td>-1.631071</td>\n",
       "      <td>-1.076339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.352381</td>\n",
       "      <td>-0.695002</td>\n",
       "      <td>-0.341666</td>\n",
       "      <td>-0.720750</td>\n",
       "      <td>-0.784080</td>\n",
       "      <td>-0.662337</td>\n",
       "      <td>-0.346178</td>\n",
       "      <td>-0.771125</td>\n",
       "      <td>-0.576133</td>\n",
       "      <td>-0.513200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60842</th>\n",
       "      <td>007e3e4ef</td>\n",
       "      <td>20230106</td>\n",
       "      <td>-0.911600</td>\n",
       "      <td>-0.917854</td>\n",
       "      <td>-0.805700</td>\n",
       "      <td>-0.774579</td>\n",
       "      <td>-0.781657</td>\n",
       "      <td>-0.823588</td>\n",
       "      <td>-1.989649</td>\n",
       "      <td>-1.315047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263931</td>\n",
       "      <td>-0.675931</td>\n",
       "      <td>-0.457655</td>\n",
       "      <td>-0.772216</td>\n",
       "      <td>-0.823486</td>\n",
       "      <td>-0.711068</td>\n",
       "      <td>-0.016452</td>\n",
       "      <td>-0.949248</td>\n",
       "      <td>-0.464884</td>\n",
       "      <td>-0.683681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60843</th>\n",
       "      <td>007e3e4ef</td>\n",
       "      <td>20230107</td>\n",
       "      <td>-0.875894</td>\n",
       "      <td>-0.888235</td>\n",
       "      <td>-0.844264</td>\n",
       "      <td>-0.733594</td>\n",
       "      <td>-0.732433</td>\n",
       "      <td>-0.799325</td>\n",
       "      <td>-1.806331</td>\n",
       "      <td>-1.392602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.352381</td>\n",
       "      <td>-0.847569</td>\n",
       "      <td>-0.689633</td>\n",
       "      <td>-0.748721</td>\n",
       "      <td>-0.793932</td>\n",
       "      <td>-0.678581</td>\n",
       "      <td>0.180065</td>\n",
       "      <td>-0.598033</td>\n",
       "      <td>0.054083</td>\n",
       "      <td>-0.592681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60844</th>\n",
       "      <td>007e3e4ef</td>\n",
       "      <td>20230108</td>\n",
       "      <td>-0.668794</td>\n",
       "      <td>-0.710521</td>\n",
       "      <td>-0.553465</td>\n",
       "      <td>-0.554281</td>\n",
       "      <td>-0.592968</td>\n",
       "      <td>-0.657792</td>\n",
       "      <td>-0.351873</td>\n",
       "      <td>-0.683528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178317</td>\n",
       "      <td>-0.618718</td>\n",
       "      <td>-0.225677</td>\n",
       "      <td>-0.643550</td>\n",
       "      <td>-0.678178</td>\n",
       "      <td>-0.566786</td>\n",
       "      <td>-0.223520</td>\n",
       "      <td>-0.241787</td>\n",
       "      <td>-0.313155</td>\n",
       "      <td>-0.232136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60929</th>\n",
       "      <td>007e3e4ef</td>\n",
       "      <td>20230403</td>\n",
       "      <td>-0.419866</td>\n",
       "      <td>-0.436801</td>\n",
       "      <td>-0.368980</td>\n",
       "      <td>-0.348329</td>\n",
       "      <td>-0.406330</td>\n",
       "      <td>-0.568828</td>\n",
       "      <td>-0.108120</td>\n",
       "      <td>-0.267552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>1.269297</td>\n",
       "      <td>1.514155</td>\n",
       "      <td>-0.209440</td>\n",
       "      <td>-0.354312</td>\n",
       "      <td>-0.392884</td>\n",
       "      <td>-1.188958</td>\n",
       "      <td>-1.683880</td>\n",
       "      <td>-0.831830</td>\n",
       "      <td>-0.093909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105304</th>\n",
       "      <td>007e3e4ef</td>\n",
       "      <td>20230404</td>\n",
       "      <td>-0.590239</td>\n",
       "      <td>-0.623707</td>\n",
       "      <td>-0.543043</td>\n",
       "      <td>-0.514320</td>\n",
       "      <td>-0.553999</td>\n",
       "      <td>-0.696208</td>\n",
       "      <td>0.240385</td>\n",
       "      <td>-0.006685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263931</td>\n",
       "      <td>1.154872</td>\n",
       "      <td>0.122289</td>\n",
       "      <td>-0.485793</td>\n",
       "      <td>-0.621532</td>\n",
       "      <td>-0.579208</td>\n",
       "      <td>-1.278643</td>\n",
       "      <td>-1.711051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105305</th>\n",
       "      <td>007e3e4ef</td>\n",
       "      <td>20230405</td>\n",
       "      <td>-0.340290</td>\n",
       "      <td>-0.346923</td>\n",
       "      <td>-0.267878</td>\n",
       "      <td>-0.221273</td>\n",
       "      <td>-0.256609</td>\n",
       "      <td>-0.497050</td>\n",
       "      <td>0.348160</td>\n",
       "      <td>0.261232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175481</td>\n",
       "      <td>1.364651</td>\n",
       "      <td>-0.109689</td>\n",
       "      <td>-0.210559</td>\n",
       "      <td>-0.366627</td>\n",
       "      <td>-0.395750</td>\n",
       "      <td>-1.237757</td>\n",
       "      <td>-1.674823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105306</th>\n",
       "      <td>007e3e4ef</td>\n",
       "      <td>20230406</td>\n",
       "      <td>-0.314786</td>\n",
       "      <td>-0.319347</td>\n",
       "      <td>-0.280385</td>\n",
       "      <td>-0.213076</td>\n",
       "      <td>-0.268915</td>\n",
       "      <td>-0.499072</td>\n",
       "      <td>0.499247</td>\n",
       "      <td>0.422385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263931</td>\n",
       "      <td>1.688856</td>\n",
       "      <td>1.050200</td>\n",
       "      <td>-0.215034</td>\n",
       "      <td>-0.364164</td>\n",
       "      <td>-0.403394</td>\n",
       "      <td>-1.199509</td>\n",
       "      <td>-1.613436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105307</th>\n",
       "      <td>007e3e4ef</td>\n",
       "      <td>20230407</td>\n",
       "      <td>-0.327028</td>\n",
       "      <td>-0.299941</td>\n",
       "      <td>-0.157395</td>\n",
       "      <td>-0.138277</td>\n",
       "      <td>-0.206360</td>\n",
       "      <td>-0.456612</td>\n",
       "      <td>0.123545</td>\n",
       "      <td>0.331736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355217</td>\n",
       "      <td>1.688856</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>-0.170281</td>\n",
       "      <td>-0.346924</td>\n",
       "      <td>-0.369951</td>\n",
       "      <td>-1.344588</td>\n",
       "      <td>-1.478586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       geohash_id   date_id       F_1       F_2       F_3       F_4       F_5  \\\n",
       "60840   007e3e4ef  20230104 -0.572895 -0.582853 -0.576396 -0.468212 -0.488368   \n",
       "60841   007e3e4ef  20230105 -0.864671 -0.868830 -0.798404 -0.719249 -0.731408   \n",
       "60842   007e3e4ef  20230106 -0.911600 -0.917854 -0.805700 -0.774579 -0.781657   \n",
       "60843   007e3e4ef  20230107 -0.875894 -0.888235 -0.844264 -0.733594 -0.732433   \n",
       "60844   007e3e4ef  20230108 -0.668794 -0.710521 -0.553465 -0.554281 -0.592968   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "60929   007e3e4ef  20230403 -0.419866 -0.436801 -0.368980 -0.348329 -0.406330   \n",
       "105304  007e3e4ef  20230404 -0.590239 -0.623707 -0.543043 -0.514320 -0.553999   \n",
       "105305  007e3e4ef  20230405 -0.340290 -0.346923 -0.267878 -0.221273 -0.256609   \n",
       "105306  007e3e4ef  20230406 -0.314786 -0.319347 -0.280385 -0.213076 -0.268915   \n",
       "105307  007e3e4ef  20230407 -0.327028 -0.299941 -0.157395 -0.138277 -0.206360   \n",
       "\n",
       "             F_6       F_7       F_8  ...      F_28      F_29      F_30  \\\n",
       "60840  -0.555685  0.089299  0.134324  ...  0.738499 -0.065663 -0.457655   \n",
       "60841  -0.783150 -1.631071 -1.076339  ... -0.352381 -0.695002 -0.341666   \n",
       "60842  -0.823588 -1.989649 -1.315047  ... -0.263931 -0.675931 -0.457655   \n",
       "60843  -0.799325 -1.806331 -1.392602  ... -0.352381 -0.847569 -0.689633   \n",
       "60844  -0.657792 -0.351873 -0.683528  ...  0.178317 -0.618718 -0.225677   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "60929  -0.568828 -0.108120 -0.267552  ...  0.001418  1.269297  1.514155   \n",
       "105304 -0.696208  0.240385 -0.006685  ... -0.263931  1.154872  0.122289   \n",
       "105305 -0.497050  0.348160  0.261232  ... -0.175481  1.364651 -0.109689   \n",
       "105306 -0.499072  0.499247  0.422385  ... -0.263931  1.688856  1.050200   \n",
       "105307 -0.456612  0.123545  0.331736  ...  0.355217  1.688856  0.934211   \n",
       "\n",
       "            F_31      F_32      F_33      F_34      F_35  active_index  \\\n",
       "60840  -0.579776 -0.640004 -0.559142 -0.518954 -0.999565     -0.061534   \n",
       "60841  -0.720750 -0.784080 -0.662337 -0.346178 -0.771125     -0.576133   \n",
       "60842  -0.772216 -0.823486 -0.711068 -0.016452 -0.949248     -0.464884   \n",
       "60843  -0.748721 -0.793932 -0.678581  0.180065 -0.598033      0.054083   \n",
       "60844  -0.643550 -0.678178 -0.566786 -0.223520 -0.241787     -0.313155   \n",
       "...          ...       ...       ...       ...       ...           ...   \n",
       "60929  -0.209440 -0.354312 -0.392884 -1.188958 -1.683880     -0.831830   \n",
       "105304 -0.485793 -0.621532 -0.579208 -1.278643 -1.711051           NaN   \n",
       "105305 -0.210559 -0.366627 -0.395750 -1.237757 -1.674823           NaN   \n",
       "105306 -0.215034 -0.364164 -0.403394 -1.199509 -1.613436           NaN   \n",
       "105307 -0.170281 -0.346924 -0.369951 -1.344588 -1.478586           NaN   \n",
       "\n",
       "        consume_index  \n",
       "60840       -0.203339  \n",
       "60841       -0.513200  \n",
       "60842       -0.683681  \n",
       "60843       -0.592681  \n",
       "60844       -0.232136  \n",
       "...               ...  \n",
       "60929       -0.093909  \n",
       "105304            NaN  \n",
       "105305            NaN  \n",
       "105306            NaN  \n",
       "105307            NaN  \n",
       "\n",
       "[94 rows x 37 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[df_all[\"geohash_id\"] == \"007e3e4ef\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 制作LSTM需要的数据格式\n",
    "\n",
    "注意这里用到了时序：get_item时，返回seq_len个时间步的所有特征，输出的label是最后一个时间步的label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每周有7天，所以先考虑以7天为一个周期\n",
    "seq_len = 7\n",
    "\n",
    "\n",
    "# 该dataset只包含一个geohash_id的数据\n",
    "class LSTMPerGeoDataset(Dataset):\n",
    "    def __init__(self, df_per_geo, seq_len):\n",
    "        self.features = df_per_geo.loc[:, feature_columns].values\n",
    "        self.labels = df_per_geo.loc[:, label_columns].values\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # feature返回值是一个seq_len*feature_num的矩阵\n",
    "        feature = self.features[index : index + self.seq_len, :]\n",
    "        if self.labels is not None:\n",
    "            # label返回值是最后一个时间步的label\n",
    "            label = self.labels[index + self.seq_len - 1, :]\n",
    "            return feature, label\n",
    "        else:\n",
    "            return feature, None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features) - self.seq_len + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测一下维度对不对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geohash_id 007e3e4ef 94\n"
     ]
    }
   ],
   "source": [
    "for i, df_per_geo in df_all.groupby(\"geohash_id\"):\n",
    "    print(\"geohash_id\", i, len(df_per_geo))\n",
    "    dataset = LSTMPerGeoDataset(df_per_geo, seq_len)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练、验证、测试集\n",
    "val_len = seq_len\n",
    "test_len = seq_len\n",
    "train_dataset = Subset(dataset, range(len(dataset) - val_len - test_len))\n",
    "valid_dataset = Subset(\n",
    "    dataset, range(len(dataset) - val_len - test_len, len(dataset) - test_len)\n",
    ")\n",
    "test_dataset = Subset(dataset, range(len(dataset) - test_len, len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94, 33), (94, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.features.shape, dataset.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7, 33), (2,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(0)[0].shape, dataset.__getitem__(0)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_data_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader制作完毕，开始设计模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMRegression(nn.Module):\n",
    "    def __init__(self, num_outputs, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTMRegression, self).__init__()\n",
    "        self.num_classes = num_outputs  # 输出值的个数\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # seq_length实际上没有用处，只是为了记录\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_1 = nn.Linear(hidden_size, 64)\n",
    "        self.fc_2 = nn.Linear(64, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始隐藏层状态和cell状态\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0))\n",
    "        # debug\n",
    "        # print(\"inside LSTM\", \"output:\", output.shape, \"hn:\", hn.shape, \"cn:\", cn.shape)\n",
    "        # print(output[0,-1,:], hn[0,0,:])\n",
    "        hn = hn.view(-1, self.hidden_size)\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc_2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM参数\n",
    "input_size = df_train.shape[1] - 4\n",
    "# hidden_size是要调的超参数，这里先随便写一个\n",
    "hidden_size = 16\n",
    "num_layers = 1\n",
    "\n",
    "# 线性层参数\n",
    "# 最终的输出值个数\n",
    "num_outputs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试维度\n",
    "x = torch.randn(batch_size, seq_len, input_size)\n",
    "model = LSTMRegression(num_outputs, input_size, hidden_size, num_layers, seq_len)\n",
    "output = model(x)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型设计完成，做一些准备工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 36\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型、优化器、损失函数\n",
    "model = LSTMRegression(num_outputs, input_size, hidden_size, num_layers, seq_len)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.1612, val loss: 0.1071\n",
      "Epoch: 1, train loss: 0.1491, val loss: 0.1224\n",
      "Epoch: 2, train loss: 0.1410, val loss: 0.1387\n",
      "Epoch: 3, train loss: 0.1349, val loss: 0.1553\n",
      "Epoch: 4, train loss: 0.1299, val loss: 0.1716\n",
      "Epoch: 5, train loss: 0.1259, val loss: 0.1864\n",
      "Epoch: 6, train loss: 0.1226, val loss: 0.1978\n",
      "Epoch: 7, train loss: 0.1198, val loss: 0.2052\n",
      "Epoch: 8, train loss: 0.1174, val loss: 0.2074\n",
      "Epoch: 9, train loss: 0.1151, val loss: 0.2046\n",
      "Epoch: 10, train loss: 0.1128, val loss: 0.1976\n",
      "Epoch: 11, train loss: 0.1106, val loss: 0.1886\n",
      "Epoch: 12, train loss: 0.1084, val loss: 0.1791\n",
      "Epoch: 13, train loss: 0.1062, val loss: 0.1692\n",
      "Epoch: 14, train loss: 0.1038, val loss: 0.1589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, train loss: 0.1014, val loss: 0.1488\n",
      "Epoch: 16, train loss: 0.0989, val loss: 0.1394\n",
      "Epoch: 17, train loss: 0.0962, val loss: 0.1303\n",
      "Epoch: 18, train loss: 0.0933, val loss: 0.1205\n",
      "Epoch: 19, train loss: 0.0902, val loss: 0.1096\n",
      "Epoch: 20, train loss: 0.0872, val loss: 0.0982\n",
      "Epoch: 21, train loss: 0.0843, val loss: 0.0883\n",
      "Epoch: 22, train loss: 0.0815, val loss: 0.0802\n",
      "Epoch: 23, train loss: 0.0788, val loss: 0.0737\n",
      "Epoch: 24, train loss: 0.0762, val loss: 0.0672\n",
      "Epoch: 25, train loss: 0.0737, val loss: 0.0611\n",
      "Epoch: 26, train loss: 0.0713, val loss: 0.0563\n",
      "Epoch: 27, train loss: 0.0689, val loss: 0.0527\n",
      "Epoch: 28, train loss: 0.0666, val loss: 0.0495\n",
      "Epoch: 29, train loss: 0.0644, val loss: 0.0467\n",
      "Epoch: 30, train loss: 0.0622, val loss: 0.0446\n",
      "Epoch: 31, train loss: 0.0601, val loss: 0.0434\n",
      "Epoch: 32, train loss: 0.0580, val loss: 0.0426\n",
      "Epoch: 33, train loss: 0.0560, val loss: 0.0408\n",
      "Epoch: 34, train loss: 0.0541, val loss: 0.0400\n",
      "Epoch: 35, train loss: 0.0521, val loss: 0.0404\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    # step是一个batch的计数器\n",
    "    for step, (b_x, b_y) in enumerate(train_data_loader):\n",
    "        b_x = b_x.float()\n",
    "        b_y = b_y.float()\n",
    "        # 前向传播\n",
    "        outputs = model(b_x)\n",
    "        loss = criterion(outputs, b_y)\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    total_train_loss /= len(train_data_loader)\n",
    "\n",
    "    # 验证集\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    for step, (b_x, b_y) in enumerate(val_data_loader):\n",
    "        b_x = b_x.float()\n",
    "        b_y = b_y.float()\n",
    "        outputs = model(b_x)\n",
    "        loss = criterion(outputs, b_y)\n",
    "        total_val_loss += loss.item()\n",
    "    total_val_loss /= len(val_data_loader)\n",
    "    print(\n",
    "        \"Epoch: {}, train loss: {:.4f}, val loss: {:.4f}\".format(\n",
    "            i, total_train_loss, total_val_loss\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69.695915 69.07723 ]\n",
      " [68.93668  67.43579 ]\n",
      " [68.65284  68.5836  ]\n",
      " [69.02105  69.02451 ]\n",
      " [69.36147  69.66171 ]\n",
      " [69.52764  70.77702 ]\n",
      " [69.85547  71.80455 ]]\n"
     ]
    }
   ],
   "source": [
    "# 测试集\n",
    "model.eval()\n",
    "for step, (b_x, _) in enumerate(test_data_loader):\n",
    "    with torch.no_grad():\n",
    "        b_x = b_x.float()\n",
    "        outputs = model(b_x)\n",
    "        print(label_scaler.inverse_transform(outputs.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一个geo的数据训练完毕，没啥问题，下面训练所有的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1140 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 56/1140 [00:40<13:03,  1.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8882/1435223515.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mb_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# 前向传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8882/2655470077.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mc_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m# debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# print(\"inside LSTM\", \"output:\", output.shape, \"hn:\", hn.shape, \"cn:\", cn.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 770\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    771\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for geohash_id, df_per_geo in tqdm(df_all.groupby(\"geohash_id\")):\n",
    "    # print(\"geohash_id\", geohash_id)\n",
    "    dataset = LSTMPerGeoDataset(df_per_geo, seq_len)\n",
    "\n",
    "    test_len = 4\n",
    "    train_dataset = Subset(dataset, range(len(dataset) - test_len))\n",
    "    test_dataset = Subset(dataset, range(len(dataset) - test_len, len(dataset)))\n",
    "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = LSTMRegression(num_outputs, input_size, hidden_size, num_layers, seq_len)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        model.train()\n",
    "        # total_train_loss = 0\n",
    "        # step是一个batch的计数器\n",
    "        for step, (b_x, b_y) in enumerate(train_data_loader):\n",
    "            b_x = b_x.float()\n",
    "            b_y = b_y.float()\n",
    "            # 前向传播\n",
    "            outputs = model(b_x)\n",
    "            loss = criterion(outputs, b_y)\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # total_train_loss /= len(train_data_loader)\n",
    "\n",
    "    # 测试集\n",
    "    model.eval()\n",
    "    for step, (b_x, _) in enumerate(test_data_loader):\n",
    "        with torch.no_grad():\n",
    "            b_x = b_x.float()\n",
    "            outputs = model(b_x)\n",
    "            res_map[geohash_id] = label_scaler.inverse_transform(outputs.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res_map), res_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果写入csv，分隔符为\\t\n",
    "date_id = [20230404, 20230405, 20230406, 20230407]\n",
    "with open(\"base_lstm.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")  # 设置分隔符为制表符\n",
    "    writer.writerow([\"geohash_id\", \"consumption_level\", \"activity_level\", \"date_id\"])\n",
    "    for geohash_id, res in res_map.items():\n",
    "        for i in range(res.shape[0]):\n",
    "            # 注意不要写反了\n",
    "            writer.writerow([geohash_id, res[i, 1], res[i, 0], date_id[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
