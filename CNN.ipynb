{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:46:04.154842Z",
     "start_time": "2023-11-25T04:46:03.984778900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    file = \"./data/train_90.csv\"\n",
    "    train_data = pd.read_csv(file)\n",
    "    return train_data\n",
    "\n",
    "def get_test_data():\n",
    "    file = \"./data/A榜/node_test_4_A.csv\"\n",
    "    test_data = pd.read_csv(file)\n",
    "    return test_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:46:04.194369500Z",
     "start_time": "2023-11-25T04:46:03.999781300Z"
    }
   },
   "id": "62e14f50eaa6077f"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calScore(loss):\n",
    "    return 1 / (1 + math.sqrt(2 * loss))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:46:04.194369500Z",
     "start_time": "2023-11-25T04:46:04.013784600Z"
    }
   },
   "id": "577f06b962afb28d"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        # Layer 1\n",
    "        self.fc1 = nn.Linear(36, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.drop1 = nn.Dropout(p=0.3)\n",
    "\n",
    "        # Layer 2\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.drop2 = nn.Dropout(p=0.4)\n",
    "\n",
    "        # Layer 3\n",
    "        self.fc3 = nn.Linear(256, 512)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.drop3 = nn.Dropout(p=0.5)\n",
    "\n",
    "        # Layer 4\n",
    "        self.fc4 = nn.Linear(512, 1024)\n",
    "        self.bn4 = nn.BatchNorm1d(1024)\n",
    "        self.drop4 = nn.Dropout(p=0.6)\n",
    "\n",
    "        # Output Layer\n",
    "        self.fc5 = nn.Linear(1024, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.drop1(F.relu(self.bn1(self.fc1(x))))\n",
    "        out = self.drop2(F.relu(self.bn2(self.fc2(out))))\n",
    "        out = self.drop3(F.relu(self.bn3(self.fc3(out))))\n",
    "        out = self.drop4(F.relu(self.bn4(self.fc4(out))))\n",
    "        out = self.fc5(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:46:04.194369500Z",
     "start_time": "2023-11-25T04:46:04.028787900Z"
    }
   },
   "id": "156e0497018991f3"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv1d(in_channels=36, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=1, stride=1)\n",
    "        self.drop1 = nn.Dropout(p=0.1)\n",
    "\n",
    "        # Layer 2\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=1, stride=1)\n",
    "        self.drop2 = nn.Dropout(p=0.1)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(128, 256)\n",
    "        self.drop3 = nn.Dropout(p=0.1)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), x.size(1), -1)\n",
    "        out = self.drop1(self.pool1(F.relu(self.conv1(x))))\n",
    "        out = self.drop2(self.pool2(F.relu(self.conv2(out))))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.drop3(F.relu(self.fc1(out)))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:46:04.194369500Z",
     "start_time": "2023-11-25T04:46:04.053594200Z"
    }
   },
   "id": "5b966670a28cc656"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, scheduler, val_loader=None, epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    output = model(inputs)\n",
    "                    loss = criterion(output, labels)\n",
    "                    val_loss += loss.item()\n",
    "                val_loss /= len(val_loader)\n",
    "            \n",
    "        scheduler.step()\n",
    "        if val_loader:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, train Loss: {running_loss/len(train_loader)}, val Loss: {val_loss}, score: {calScore(val_loss)}')\n",
    "        else:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, train Loss: {running_loss/len(train_loader)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:46:04.194369500Z",
     "start_time": "2023-11-25T04:46:04.066435700Z"
    }
   },
   "id": "c68582c3d48f861a"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def predict(model, test_data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(test_data)\n",
    "    return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:46:04.194369500Z",
     "start_time": "2023-11-25T04:46:04.077806400Z"
    }
   },
   "id": "34782eaf2beacea5"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102600, 38)\n",
      "(4560, 36)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "\n",
    "d = get_train_data()\n",
    "t = get_test_data()\n",
    "ans = []\n",
    "data = d.iloc[:, 1:]\n",
    "test = t.iloc[:, 1:]\n",
    "# X = data.iloc[:, 1:37]\n",
    "# X=RobustScaler().fit_transform(X)\n",
    "scaler = RobustScaler()\n",
    "# data=RobustScaler().fit_transform(data)\n",
    "data.iloc[:, :36] = scaler.fit_transform(data.iloc[:, :36])\n",
    "data = pd.concat([data.iloc[:, :36], data.iloc[:, 36:]], axis=1).values\n",
    "test=RobustScaler().fit_transform(test)\n",
    "# y = data.iloc[:, 37:]\n",
    "# y = np.array(y.values)\n",
    "# scaler = StandardScaler()\n",
    "# y = scaler.fit_transform(y)\n",
    "\n",
    "print(data.shape)\n",
    "print(test.shape)\n",
    "print(type(data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:46:05.007014100Z",
     "start_time": "2023-11-25T04:46:04.092810Z"
    }
   },
   "id": "465b9a88e56feae9"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# 划分训练集和验证集，使用sklearn的train_test_split函数\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "val, my_test = train_test_split(val, test_size=0.5, random_state=43)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:46:05.086707200Z",
     "start_time": "2023-11-25T04:46:04.993915Z"
    }
   },
   "id": "9e62bc020195eb22"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "train_x = train_data[:, :36]\n",
    "train_y = train_data[:, 36:]\n",
    "val_x = val[:, :36]\n",
    "val_y = val[:, 36:]\n",
    "my_test_x = my_test[:, :36]\n",
    "my_test_y = my_test[:, 36:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:46:05.086707200Z",
     "start_time": "2023-11-25T04:46:05.074569800Z"
    }
   },
   "id": "66a8ae6af5d7ef05"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82080, 36)\n",
      "(82080, 2)\n",
      "(10260, 36)\n",
      "(10260, 2)\n",
      "(10260, 36)\n",
      "(10260, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(val_x.shape)\n",
    "print(val_y.shape)\n",
    "print(my_test_x.shape)\n",
    "print(my_test_y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:46:05.104790300Z",
     "start_time": "2023-11-25T04:46:05.086707200Z"
    }
   },
   "id": "de4a887111d62039"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, train Loss: 884.4234476416282, val Loss: 48.51936535718964, score: 0.0921589008292849\n",
      "Epoch 2/30, train Loss: 13.242033998542857, val Loss: 7.294661969673343, score: 0.20748621238438864\n",
      "Epoch 3/30, train Loss: 4.0067471425481305, val Loss: 3.8704810462346892, score: 0.2643922970231967\n",
      "Epoch 4/30, train Loss: 3.023655709819259, val Loss: 2.883815364139836, score: 0.2939802364686252\n",
      "Epoch 5/30, train Loss: 2.3779641478975244, val Loss: 2.3945151509308236, score: 0.3136383780918273\n",
      "Epoch 6/30, train Loss: 2.1841910752551947, val Loss: 1.921187566547859, score: 0.33781527177071563\n",
      "Epoch 7/30, train Loss: 1.837560369960987, val Loss: 1.9612675054771145, score: 0.3355097773412285\n",
      "Epoch 8/30, train Loss: 1.6508639683233244, val Loss: 2.1919955015182495, score: 0.32322728490379976\n",
      "Epoch 9/30, train Loss: 1.7849375629722144, val Loss: 1.8287253001841104, score: 0.34335397787195443\n",
      "Epoch 10/30, train Loss: 1.5370462646365537, val Loss: 1.415054085778027, score: 0.37281541336247004\n",
      "Epoch 11/30, train Loss: 1.229918736906438, val Loss: 1.2310487177313827, score: 0.3892402762457795\n",
      "Epoch 12/30, train Loss: 1.1310536761150183, val Loss: 1.1770817433915488, score: 0.3945818622317177\n",
      "Epoch 13/30, train Loss: 1.4063365390738967, val Loss: 1.117921391638314, score: 0.4007576754912414\n",
      "Epoch 14/30, train Loss: 1.0073943808442707, val Loss: 1.0464377076160618, score: 0.4087175579125666\n",
      "Epoch 15/30, train Loss: 1.0035323281525823, val Loss: 1.3937656923038204, score: 0.3745893305114849\n",
      "Epoch 16/30, train Loss: 1.0801617249707196, val Loss: 1.0513076026265213, score: 0.4081566472701316\n",
      "Epoch 17/30, train Loss: 0.8717025572265792, val Loss: 1.1464085855135104, score: 0.39774002076598153\n",
      "Epoch 18/30, train Loss: 0.9145087071482637, val Loss: 0.7928761178400459, score: 0.44262152310147224\n",
      "Epoch 19/30, train Loss: 0.7466915060426588, val Loss: 0.8297717004287534, score: 0.43701849685564\n",
      "Epoch 20/30, train Loss: 0.6845398442210439, val Loss: 0.7243071460142368, score: 0.45380617614267776\n",
      "Epoch 21/30, train Loss: 0.6080280683493688, val Loss: 1.2615036695468715, score: 0.38633939041682497\n",
      "Epoch 22/30, train Loss: 0.5869468390198883, val Loss: 1.0717769585004666, score: 0.40582964813297745\n",
      "Epoch 23/30, train Loss: 0.5945829632126283, val Loss: 0.6324990769711937, score: 0.47064994752493605\n",
      "Epoch 24/30, train Loss: 0.5388317684703898, val Loss: 0.578271334491125, score: 0.48182861945973676\n",
      "Epoch 25/30, train Loss: 0.5399122939117229, val Loss: 0.6048706900782701, score: 0.47621713545077854\n",
      "Epoch 26/30, train Loss: 0.5145162391328366, val Loss: 0.692909968335454, score: 0.45930372932788965\n",
      "Epoch 27/30, train Loss: 0.5670200927977993, val Loss: 0.7273636329464797, score: 0.45328434518621763\n",
      "Epoch 28/30, train Loss: 0.4585526228136734, val Loss: 0.5229821415936075, score: 0.4943828339615774\n",
      "Epoch 29/30, train Loss: 0.44726477062033715, val Loss: 0.5894071808675441, score: 0.4794479419181605\n",
      "Epoch 30/30, train Loss: 0.49252322334738163, val Loss: 0.49937588485275825, score: 0.5001561262427765\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "X_train = torch.Tensor(train_x)\n",
    "X_test = torch.Tensor(test)\n",
    "y_train = torch.Tensor(train_y)\n",
    "X_val = torch.Tensor(val_x)\n",
    "y_val = torch.Tensor(val_y)\n",
    "X_my_test = torch.Tensor(my_test_x)\n",
    "y_my_test = torch.Tensor(my_test_y)\n",
    "\n",
    "batch_size = 256\n",
    "epoch_num = 30\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train(model, train_loader, criterion, optimizer, scheduler, val_loader=val_loader, epochs=epoch_num)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:47:36.983053Z",
     "start_time": "2023-11-25T04:46:05.104790300Z"
    }
   },
   "id": "6a22be75b7474160"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "my_test_dataset = TensorDataset(X_my_test)\n",
    "my_test_loader = DataLoader(my_test_dataset)\n",
    "# 进行预测\n",
    "predictions = []\n",
    "for test_data in my_test_loader:\n",
    "    pred = predict(model, test_data[0])\n",
    "    predictions.append(pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:47:42.216825300Z",
     "start_time": "2023-11-25T04:47:36.969050400Z"
    }
   },
   "id": "79a8819d8a82c4ce"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68.20496  66.55721 ]\n",
      " [67.41379  65.77437 ]\n",
      " [73.320854 82.62299 ]\n",
      " ...\n",
      " [67.67718  66.11994 ]\n",
      " [71.65931  75.46871 ]\n",
      " [67.7411   62.01935 ]]\n"
     ]
    }
   ],
   "source": [
    "p = torch.cat(predictions, dim=0).numpy()\n",
    "# p = torch.tensor(RobustScaler().inverse_transform(p)).numpy()\n",
    "print(p)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:47:42.292355500Z",
     "start_time": "2023-11-25T04:47:42.222330600Z"
    }
   },
   "id": "f34ea9b9fcec8636"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5179920198605967\n"
     ]
    }
   ],
   "source": [
    "mse = np.mean((my_test_y - p) ** 2)\n",
    "score = calScore(mse)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:47:42.319869Z",
     "start_time": "2023-11-25T04:47:42.252678Z"
    }
   },
   "id": "2ef239a715d14a92"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(X_test)\n",
    "test_loader = DataLoader(test_dataset)\n",
    "\n",
    "# 进行预测\n",
    "predictions = []\n",
    "for test_data in test_loader:\n",
    "    pred = predict(model, test_data[0])\n",
    "    predictions.append(pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:47:44.586882800Z",
     "start_time": "2023-11-25T04:47:42.265995600Z"
    }
   },
   "id": "27cb097e2ca54c76"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4560, 2)\n",
      "[68.574844 60.86804 ]\n"
     ]
    }
   ],
   "source": [
    "# 将包含 PyTorch Tensor 的列表连接成一个 4560x2 的矩阵\n",
    "p = torch.cat(predictions, dim=0).numpy()\n",
    "# 打印矩阵的形状和第一个元素\n",
    "print(p.shape)\n",
    "print(p[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:47:44.609202Z",
     "start_time": "2023-11-25T04:47:44.587887Z"
    }
   },
   "id": "a8223ac058f7769d"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "ans = []\n",
    "for i in range(len(p)):\n",
    "        s = str(t['geohash_id'].iloc[i])\n",
    "        s += '\\t'\n",
    "        s += str(p[i][1])\n",
    "        s += '\\t'\n",
    "        s += str(p[i][0])\n",
    "        s += '\\t'\n",
    "        s += str(t['date_id'].iloc[i])\n",
    "        ans.append(s)\n",
    "\n",
    "df = pd.DataFrame(data=ans, columns=[\"geohash_id\\tconsumption_level\\tactivity_level\\tdate_id\"])\n",
    "df.to_csv(\"CNN.csv\", index=False)\n",
    "print(\"finished\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T04:47:44.815107100Z",
     "start_time": "2023-11-25T04:47:44.609202Z"
    }
   },
   "id": "7cee654731034026"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
